%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%                           Tarvo Reinpalu                               %%%%
%%%% Maximizing UITableView scrolling performance in Pairby iOS Application %%%%
%%%%                             20.02.2017                                 %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%
% General configuration %
%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{itk_thesis_eng}
\usepackage{cite}
\usepackage{parskip} % Define paragraph line-breaks
\usepackage{mathptmx} % Apply Times New Roman font
\usepackage[toc, xindy, style=list, nonumberlist]{glossaries}
\usepackage{url}
\graphicspath{{img/}}
\linespread{1.5}
\usepackage{hyperref}
\usepackage{tabularx} % Better tables (fill width)

\usepackage{titlesec} % Make new sections start with a 1.5cm margin
\newcommand{\sectionbreak}{\vspace*{1.5cm}}

\usepackage{minted} % Code coloring
\usepackage{xcolor}
\usemintedstyle{vs}
\definecolor{codebg}{gray}{0.96}
\setminted{
  bgcolor=codebg,
  tabsize=2,
  fontsize=\scriptsize,
  breaklines=true,
  escapeinside=\#\#}

\begin{document}

%%%%%%%%%%%%%%%%%%%%
% Thesis constants %
%%%%%%%%%%%%%%%%%%%%
\begin{itkTitlePage}
\title{Optimizing UITableView in the Pairby iOS application}
\paper{Diploma thesis}
\author{Tarvo Reinpalu}
\curriculum{IT systems development curriculum}
\supervisor{Gary Planthaber}
\consultant{Toomas Lepikult}
\end{itkTitlePage}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Pre-content chapters %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%
% Author declaration %
%%%%%%%%%%%%%%%%%%%%%%
\itkMakeAuthorDeclaration

%%%%%%%%%%%%%%%%%%%%%
% Table of contents %
%%%%%%%%%%%%%%%%%%%%%
\clearpage
\thispagestyle{empty}
\tableofcontents
\newpage



%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Content chapters %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% Introduction % % REVIEWED | T: + | G:   %
%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\introduction{Introduction}
Verbal feedback from smartphone users, online studies regarding the priorities of mobile application users\cite{AppSpeedStudyHP}\cite{AppSpeedStudyApigee} and the author's personal preference all indicate that mobile applications' performance is important. This is not a recent trend. The expectation of having no input lag has been around as long as the technological devices that require user input have existed.\cite{NielsenUsabilityEngineering} Even the slightest delay (anything above 0.1s) is not considered instantaneous by users and anything above 1 second results in the user's flow of thought to be interrupted and focus to be lost.\cite{NielsenUsabilityEngineering} That is enough information to conclude that not only do the users expect a smooth and fast user experience, it is actually necessary to retain the user's attention.

Pairby's mobile applications are no exception when it comes to that good user experience requirement. Pairby, of which the author is a co-founder of, is a mobile dating service which has applications on both iOS and Android platforms. The thesis subject is directly derived from the author's interest in solving a performance issue in the iOS application.

\introductionSubsection{Description of the problem}
Pairby iOS application contains, among other views, a multitude of different vertically scrolling views, which can contain a theoretically unlimited amount of subviews. One of those vertically scrolling views is the message list view, which this thesis will focus on. The message list view's purpose is to render a list of messages using a UITableView component, in which each message could contain either text or images.

Pairby iOS application's first prototype version was scratched due to a massive performance issue in the message list view. Namely, scrolling up or down at a rapid speed in that view was so resource consuming on any older Apple device it froze the whole user interface. This behavior was deemed unacceptable by the Pairby team and development of that prototype was halted. It became apparent to the developer that something fundamental had been done wrong both in the development of the user interface and in the handling of the data in the model.

At the time of starting the thesis test project, the development of the new iOS application for Pairby had started, but a solution to the performance issue had not yet been found.

\introductionSubsection{Goal of the thesis}
The goal of the thesis was to analyze a number of different optimizations that can be applied to the UITableView component and its subviews in order to improve the responsiveness of the user interface and through that make the application offer a good user experience. All optimizations were applied in a sequence, where the next one would complement the previous one, creating a more performant view after each optimization. The user interface was designed with the Pairby real-life application in mind: visually, the test project and the real life application share many similarities.

Each optimization had to go through a pre-defined programmatic scrolling test while different aspects of the device's were monitored. The monitoring resulted in large data sets about the frame rate, CPU usage and memory usage, which were then analyzed and combined into general data about the test. These generalized values were then compared against existing results and the optimization's effectiveness was decided based on that.

The expected end result was a UITableView component that is performant even when the scroll behavior exceeds the boundaries of realistic use cases.

%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% Specifications % % REVIEWED | T: + | G:   %
%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Specifications}
The test project was meant to broadly mimic the user interface of the real-life iOS application of Pairby. This could only be possible if there were a number of requirements set to the project's test data and user interface.

\subsection{Test data requirements}
The test data contained 500 message type objects. The data was stored in JSON format and saved to a file which could then be loaded into the iOS test project using the XCode assets interface.

\subsubsection*{Message type}
The type definition for the Message object.

\vskip.2in

\begin{table}[H]
  \caption{Message type definition}
  \begin{tabularx}{\textwidth}{| l | l | l | X |}
    \hline
    Property & Type & Required & Description \\
    \hline
    messageId & Integer & true & A unique identifier generated from a sequence starting at 0 with an increment of 1. \\
    direction & String & true & Can be either "in" or "out", representing the direction of the message relative to the current user. \\
    message & String & false & Text message's text. Not present in media messages. \\
    mediaItems & String[] & false & Media message's media URLs. Not present in text messages. \\
    \hline
  \end{tabularx}
\end{table}

\subsubsection*{Text message requirements}
Text messages can vary in both width and height. Width is dependant on both the length of the longest line of text in the message text and the screen width. The height depends on the number of lines in the text. The number of lines in turn depends on the screen width and whether the text is long enough to require text wrapping or contains line breaks.

To simulate real life scenarios, text messages of three different widths and heights were created. These test messages consisted of horizontally slim single line messages, medium width two line messages and wide three line messages. To guarantee similar data rendering across different devices and screen widths, line breaks were used to create multi-line messages. The other option would have required word-wrapping, which would have depended on the width of the screen on the device and not produced the same number of lines on across all devices.

\subsubsection*{Media message requirements}
In the Pairby real life application, media messages can contain up to 6 media items that can either be static images (JPG), animated images (GIF) or videos (MP4).

Inside the messages list view, however, the media items are restricted into two different formats: static and animated images. Video thumbnails, which are the displayed in the message list view, are still static images. This reduces the required different media types down to static and animated images.

To simplify and speed up the building of different benchmark views, the maximum number of media items in a message was reduced to 3, instead of 6. Therefore the number of media items inside a media message could be 1 to 3 (inclusive).

To simulate real conditions, all media should be loaded from Pairby servers through the network. This also raised the requirements of running all the tests on the same network, while closely monitoring the network usage (all the tests had to be run under similar network load, to not increase the number of different factors that could affect the results).

\subsection{Test data generation}
Test data for the project was generated in a separate script, which is written in JavaScript and executed in a Node.JS environment. The output of the script was a JSON file that contained an array of message type objects.

\subsubsection*{Message generation}
The number of messages to be generated was configurable and was set to 500 for the purposes of this test project.

The type (text or media) of each message was decided using a semi-random probability technique: a random number from 0 to 1 was generated and compared against a configurable parameter called "media message probability". If the generated number was less than or equal to the "media message probability" parameter, the message type was set to be media message and therefore its "mediaItems" parameter was filled out. If the generated number happened to be larger than the previously defined parameter, then the message was set to be of text type and its "message" property was filled out. The test dataset was generated with the media message probability set to 0.25 (25\%).

The message ID was simply set to the sequence number in the running loop (which started at zero and ended at the number of generated messages minus 1). For the 500 messages generated for the purpose of this test, the IDs ranged from 0 to 499 (inclusive).

Each message's direction was also defined through a random number generator and was set to have an equal chance of either being outbound or inbound. This process was similar to the way the message type was chosen: a random number between 0 and 1 was generated and it was compared against 0.5, if was less than or equal to 0.5, "direction" property was set to out, otherwise it was set to "in". This would in theory mean that half of the messages would be outbound and the other half inbound, but not in a pre-determined order.

\subsubsection*{Text message content generation}
As defined in the specifications, there were three different text messages, all of which were different in height and width. The text for each three different types was static (pre-defined). Selecting one of the three different texts (which would determine both the width and height) was random and each message type had an equal chance of being selected. A random whole number between 1 and 3 (inclusive) was generated, if it was 1, then the short one line message was chosen. If the generated number was 2, then the two line medium width text was chosen. If the number was 3, then the three line and widest text was selected.

\subsubsection*{Media message content generation}
In order to properly mimic the real life scenarios in the message list view all media had to be loaded from the Pairby media servers. The ability of uploading media to the Pairby media servers through the public Pairby API was built to the data generator, which then returned the URLs to the uploaded files.

The sample media files consisted of 100 static images of JPG format and 10 animated images of GIF format. All of those images were uploaded to the Pairby media servers.

The number of media items to include with a specific media message was a random number between 1 and 3 (inclusive).

The URL or URLs that would represent the media items were chosen randomly and duplicates were not prevented. Therefore there could be media messages that contained the same media item multiple times. Even though this would not be possible in the real life Pairby application, there was no direct reason to prevent it from happening either, for it should still work as expected and not affect the performance that much.

\subsection{User interface requirements}
As stated in the introduction to this section, the user interface was meant to mimic Pairby iOS application's messaging user interface.

\subsubsection*{Common design elements}
Both the text and media message views had to have rounded corners with a radius of 15 points and a border of gray colour (\mintinline{apacheconf}{#ECEFF1}) with a width of 1 point.

\subsubsection*{Text message}
The text message view had to be able to handle line breaks (increase in height to display all lines). The background color for inbound and outbound messages should be different: teal (\mintinline{apacheconf}{#4DB6AC}) for outbound, gray (\mintinline{apacheconf}{#ECEFF1}) for inbound.

\subsubsection*{Media message}
Media message view stylings were dependant on the number of images they contain, as is the case in the real-life Pairby iOS application.

\paragraph*{1 media item}
A single media item message displayed the image with a width and height of 180 points.

\paragraph*{2 media items}
A two media item message displayed the images side by side, with the image widths and heights being 90 points. The gap between the media items was 5 points.

\paragraph*{3 media items}
A three media item message displayed the images side by side, with the image widths and heights being 90 points. The gap between the media items was 5 points.

%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% Measuring performance % % REVIEWED | T: + | G:   %
%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Measuring performance}
To gather quantifiable information and not base comparison points on visual judgement, there needed to be a way to run reproducible tests and gather number based statistics from each test. This was achieved in two different parts: the creation of a repeatable test case (programmatic scrolling) and using different kinds of software to retrieve and save information about the system.

\subsection{Repeatable test case}
The repeatable test case's purpose was to simulate scrolling and do it in the exact same way every time the test is executed.

To achieve this, UITableView's \mintinline{swift}{setContentOffset(contentOffset, animated: true)} function was used along with a repeating \mintinline{swift}{Timer}. The \mintinline{swift}{Timer} fired every 0.4 seconds and forced the view to scroll, starting from the top, towards the bottom. The scrolling was purposefully not linear: starting from 100 points, every time the timer fired and the view was scrolled, the scroll amount increased by 30 points. This means that the first time the timer fired, the \mintinline{swift}{setContentOffset(contentOffset, animated: true)} was fired with a 100 point increase in the vertical content offset. The next time, the increase was 130 points and after that, 160 points.

\subsection{Measuring test case performance}
A multitude of metrics were monitored to get a good overview of the performance and efficiency of the UITableView. In addition to measuring frame rates and scroll test durations, the system resource usages were monitored. The purpose of that was to reveal if and how the performance is dependant on the system's resource usage. The monitored resources were processor (CPU), graphics processor (GPU) and memory (RAM) usage.

Measuring frame rates was programmatic and handled by a custom implementation of the FPSCounter\cite{FPSCounterGithub} library. The scroll test duration was also measured programmatically.

In addition to just measuring frame rate, a metric called frame rate stability was introduced. The simplified definition for that is "time spent within 20\% of the average frame rate". In the background, it was calculated as the percentage of measured frame rate points that were within 20\% of the average frame rate. The difference is that this might not directly translate into time spent in the stable zone, as frame rate measurements were taken at a 0.5 second interval.

The rest of the metrics, namely CPU, GPU and RAM usage were measured using a third-party software called GameBench\cite{GameBenchHome}. The software required very little setup and offered very few configuration options. All that was needed was to start the monitoring process and then end it when the test was finished and it would display the measured data in an exportable form. The data included the three data set points mentioned earlier.

\subsection{Analyzing gathered metrics}
In order to get a comprehensible overview of the gathered data, the large sets of data had to be trimmed down to a small number of data points. For frame rates, it was decided to use average frame rates and frame rate stability. For processor, graphics processor and memory usage, only averages were calculated.

This resulted with a list of the following measurement points for each test:
\begin{itemize}
  \item Duration (seconds)
  \item Average frame rate
  \item Frame rate stability
  \item Average processor usage
  \item Average graphics processor usage
  \item Average memory usage
\end{itemize}

\subsection{Test device}
The tests were run on a iPod Touch 5G, as it is a good example of a low-powered device. The 5th generation iPod touch has a retina display (resolution 1136x640)\cite{AppleIPodTouch5G} while still having a very weak processor (dual core Apple A5 underclocked to 800 MHz)\cite{MacObserverUnderclock}. All of this means all the performance optimizations would have a strong effect that is easy to detect in the measured data.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% Used third party libraries % % REVIEWED | T: + | G:   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Used third party libraries}
Creating every aspect from scratch in the test project would have been too large of a task to cover in this thesis, therefore third-party solutions were used to simplify some tasks. The affected aspects were for example JSON parsing, image loading and caching, detailed logging and in-code constraint creation.

\subsection{JASON}
JASON is a faster JSON deserializer written in Swift.\cite{JASON} The sole purpose for this library in the test project was to turn the test data from JSON form into Swift objects. Even though deserialization of the JSON data could have been done using Swift's built in capabilities, JASON allowed the same goal to be achieved with much shorter and more readable code.

\subsection{SnapKit}
SnapKit is a DSL to make Auto Layout easy on both iOS and OS X.\cite{SnapKit} SnapKit was used extensively in the test project to create constraints in the code, rather than in the storyboard. Creating layout constraints in the code had many benefits over creating them in the storyboards. For example, it removed the system overhead brought in by the processing of storyboards. It also gave the engineer very precise control over each constraint and provided an overview of all constraints that exist and when they will be created. Storyboards would have only had the benefit of providing the engineer with a graphical interface in which to create those constraints.

\subsection{PINRemoteImage}
PINRemoteImage, also known as PINRemoteImageManager, is an image downloading, processing and caching manager.\cite{PINRemoteImage} PINRemoteImage was used for the exact three things brought out in the library's description: it downloaded the images, allowed them to be processed and then stored safely in a disk cache. All that with minimal effort from the library user. Downloading images would have been trivial with the Swift's built in tools as well, but processing and caching would have been more difficult. The ability to process the images is especially useful as it allows the images to be scaled down if necessary, which in turn makes the image smaller in dimensions and the file smaller in size. The library's cache manager is also powerful and extremely useful as it provided the option to cache different, processed, versions of the same image, including the original one. The different versions were distinguished by a string key passed to the process function.

\subsection{XCGLogger}
XCGLogger is a debug log framework for use in Swift projects.\cite{XCGLogger} XCGLogger improved Swift's built-in logging mechanism by adding a lot of useful, yet optional, information about every log statement. For example, it displayed the thread name on which the log statement was executed on, without forcing the engineer to explicitly print out the thread name. The exact same went for function names, file names and line numbers. Its uses and benefits in the test project are the same as the examples brought out previously (such as the identification of threads and functions).

\subsection{FLAnimatedImageView}
FLAnimatedImage is a performant animated GIF engine for iOS.\cite{FLAnimatedImageView} FLAnimatedImageView does one thing that the iOS's built in \mintinline{swift}{UIImageView} was not able to do: play GIFs. This library was very important to both the test project and the actual Pairby application for that exact reason.

\subsection{FPSCounter}
FPSCounter is a small library to measure the frame rate of an iOS Application.\cite{FPSCounterGithub} It was used for that same purpose in the test project. The data gathered by it was used to analyze the performance of each optimization method (and/or test case).

%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% Comparison points % % REVIEWED | T:   | G:   %
%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Comparison points}
In order to accurately compare performance changes in the test project, a set of starting points were needed. It was decided to use a best case scenario and a worst case scenario as two starting comparison points. Each of the tests had to be and were run with the exact same data set, including the best and worst case scenario ones.

\subsection{Best case scenario}
\label{sec:best-case-scenario}
The best case scenario had the simplest possible subviews and had to goal to display the best possible performance. To create the simplest subviews, media items were omitted from the equation and built-in UITableView \mintinline{swift}{UITableViewCell} were used, all of which displayed plain text.

To achieve a text-only message list, all media messages were replaced at runtime with a text message with text \mintinline{text}{Media message with ID [N]} where \mintinline{text}{N} was the ID of the message. Text messages were displayed as they would be normally.

Running the performance tests on this view yielded the following results:
\itkIncludeImage{test-0-1}{Performance test results for the best case scenario}

As presumed before running the tests, this test case displayed the best possible performance. The test suite was run twice and the averages of the two test cases were taken as final comparable results. The average frame rate was exactly 60 frames per second, which is the iOS golden standard\cite{IntroducingAsyncDisplayKit}. Both CPU and GPU usage remained fairly low, with the averages being 16\% and 24\% respectively. This means neither of the processors were stressed when still providing the user with the smoothest possible experience.

\subsection{Worst case scenario}
\label{sec:worst-case-scenario}
The worst case scenario had no known optimizations applied and did not follow any common performance boosting patterns (for example cell reusing). The data set was the same as the one provided in the best case scenario one, but media items were not omitted in this case. All messages were displayed as was specified in the user interface specifications.

To render both text and media message views, two different view classes that inherited from \mintinline{swift}{UITableViewCell} were created. One for displaying text messages, the other for displaying media messages.

Running the performance tests on this view yielded the following results:
\itkIncludeImage{test-0-2}{Performance test results for the worst case scenario}

The test results were not surprising and accomplished the previously set goal of showing horrendous performance. The average frame rate had dropped to 26, compared to the 60 measured in the best case scenario tests. Both the processor and the graphics processor were noticeably more stressed with the average usage being 69\% and 66\% respectively. Surprisingly, the average memory usage for the application went down by 3 megabytes, even though images were brought into the tests. That can be explained by making the assumption that the images are handled by the system and do not count towards the memory usage of the application. Another theoretical explanation would be that the images are so small (around 50 kilobytes each) that they do not affect the total memory usage that much, but this is not true for GIF-s, that are about one megabyte each.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% Performance optimizations % % REVIEWED | T:   | G:   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Performance optimizations}
All performance optimizations were built on top of one another in a way that each optimization complemented the previous one. The base for that project was the worst case scenario project. 

%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% Reusing cells % % REVIEWED | T: + | G:   %
%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Reusing cells}
Reusing the cells was chosen as a so-called starting point for all the optimizations due to the fact it was one of the more widely known ones. That capability was already built into the UITableView control by Apple and has been there ever since iOS 2.0.\cite{HackingWithSwiftCellReuse}

\subsubsection*{Theoretical benefits}
Reusing cells means that every time a new message enters the view, instead of creating a new instance of the cell class, an existing object created from that class is used. This reuse of cell objects is a performance enhancement because it eliminates the overhead of cell creation.\cite{AppleCharacteristicsOfCellObjects}

This enhancement required fundamental changes to be made to the existing cell classes. Views needed to have the ability to re-adjust themselves during runtime in order match their design to the type of message they were meant to display. Previously, views only needed to define their layout state once, upon initialization, and would no longer have to readjust themselves.

\subsubsection*{Performance changes}
Running the performance tests yielded the following results:
\itkIncludeImage{test-1}{Performance test results after applying cell reuse optimizations}

The optimization certainly had a positive impact on the performance of the project, compared to the worst case scenario which was the starting point. Average frame rate increased by 8.9 frames per second, while both the processor's and graphic processor's average usage decreased by 12.78 and 2.95 percent respectively. The duration for the test case also decreased from 105.5 seconds to 92.7 seconds, displaying a time decrease of 12.8 seconds. This was directly tied to the average frame rate, as all the necessary frames were rendered faster. Average memory usage did show an increase of 3 megabytes, from 28 to 31 megabytes, but this change is small enough to classify it as minor and label it as "did not change".

\subsubsection*{Code examples}
Apple has already built support for cell reusing into the UITableView component, meaning the implementation on the UITableView side of things required little effort from the software engineer. All the reusable cell classes had to be registered to the instance of the UITableView class they are meant to be reused in using the \mintinline{swift}{register(_:forCellReuseIdentifier:)} function.\cite{AppleRegisterMethod} After registering, they can be requested from the UITableView instance by using the \mintinline{swift}{dequeueReusableCell(withIdentifier:)} function.\cite{AppleDequeueReusableCellMethod}

\newpage % Break to new page, to keep the image and text together
Below is an example on how to register cell classes to be reused in a specific UITableView instance.
\begin{listing}[H]
  \caption{Registering cells to be reused on a specific UITableView instance}
  \begin{minted}{swift}
    self._tableView.register(ReusingCells_TextCell.self, forCellReuseIdentifier: "ReusingCells_TextCell")
    self._tableView.register(ReusingCells_MediaCell.self, forCellReuseIdentifier: "ReusingCells_MediaCell")
  \end{minted}
\end{listing}

This is an example on how to query reusable cells in the same UITableView instance.
\begin{listing}[H]
  \caption{Using recycled cells in the test project}
  \begin{minted}{swift}
    func tableView(_ tableView: UITableView, cellForRowAt indexPath: IndexPath) -> UITableViewCell {
      let message = self._messages[indexPath.row]
      let cellIdentifier = (message.mediaItems == nil) ? "ReusingCells_TextCell" : "ReusingCells_MediaCell"
      let cell = self._tableView.dequeueReusableCell(withIdentifier: cellIdentifier) as! ReusableCell
      cell.updateFromMessage(message: message)
      return cell
    }
  \end{minted}
\end{listing}

%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% Static layouts % % REVIEWED | T: + | G:   %
%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Making cell views' layouts static}
Making cell views' layouts static was an idea proposed by this thesis' supervisor Gary Planthaber. The idea behind it was that instead of two different cell classes that display mutating views which adjust themselves to display all the different message types there would be eight different cell classes that would display statically laid out views.

List of necessary cell views to make views with a static layout possible:
\begin{itemize}
  \item Inbound text message view
  \item Outbound text message view
  \item Inbound media item view (1 media item)
  \item Outbound media item view (1 media items)
  \item Inbound media item view (2 media items)
  \item Outbound media item view (2 media items)
  \item Inbound media item view (3 media items)
  \item Outbound media item view (3 media items)
\end{itemize}

\subsubsection*{Theoretical benefits}
The theoretical performance enhancing effect of this optimization was eliminating the overhead of creating and disposing of both subviews and layout constraints. This optimization complements the previous one, as they both work towards the same goal of removing unnecessary view creations, mutations and deletions. When the previous optimization only recycled the larger parent (cell) views, this change has the goal to also optimize all of the inner views and constraints.

\subsubsection*{Performance changes}
Running the performance tests yielded the following results:
\itkIncludeImage{test-2}{Performance test results after making cell views' layouts static}

The optimization had a strong effect on the average frame rate which increased by 5.7 frames per second. The frame rate stability also saw an increase of 6.4 percent. The changes in the average processor, graphics processor and memory usage were so slight, they can be classified as staying the same. Overall, this optimization increased the frame rate by 16\% and frame rate stability by 6.4\% without affecting the resource usage.

\subsubsection*{Code examples}
This also changed the code for reusing the cells. After re-working the cell views, 8 different views needed to be registered to be recycled and that in turn made the logic of querying reusable cells a bit more difficult.

Below is the new code where the 8 new views are registered in the main UITableView instance:
\begin{listing}[H]
  \caption{Registering static cell views to a UITableView instance}
  \begin{minted}{swift}
    self._tableView.register(StaticCells_TextCell_In.self, forCellReuseIdentifier: "StaticCells_TextCell_In")
    self._tableView.register(StaticCells_TextCell_Out.self, forCellReuseIdentifier: "StaticCells_TextCell_Out")
    self._tableView.register(StaticCells_MediaCell_1_In.self, forCellReuseIdentifier: "StaticCells_MediaCell_1_In")
    self._tableView.register(StaticCells_MediaCell_1_Out.self, forCellReuseIdentifier: "StaticCells_MediaCell_1_Out")
    self._tableView.register(StaticCells_MediaCell_2_In.self, forCellReuseIdentifier: "StaticCells_MediaCell_2_In")
    self._tableView.register(StaticCells_MediaCell_2_Out.self, forCellReuseIdentifier: "StaticCells_MediaCell_2_Out")
    self._tableView.register(StaticCells_MediaCell_3_In.self, forCellReuseIdentifier: "StaticCells_MediaCell_3_In")
    self._tableView.register(StaticCells_MediaCell_3_Out.self, forCellReuseIdentifier: "StaticCells_MediaCell_3_Out")
  \end{minted}
\end{listing}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% Manual cell height calculations % % REVIEWED | T: + | G:   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Manual cell height calculations}\label{subsection:ManualCellHeightCalculations}
Up to this point in the test project, the cell height calculations had been done automatically by the UITableView instance's underlying logic. This was activated purposefully by setting the UITableView instance's property \mintinline{swift}{rowHeight} to \mintinline{swift}{UITableViewAutomaticDimension}. According to a multitude of sources, these automatic calculations are often slow and it's sensible to override them with manual calculations that are more efficient.\cite{PerfectSmoothScrollingInUITableViews}\cite{HowToMakeDynamicTableViewCellHeight}\cite{MediumSmoothScrollPrearo}

\subsubsection*{Theoretical benefits}
Calculating the cell height manually using efficient calculations should improve the performance when scrolling at high speeds or when the whole UITableView is refreshed using the \mintinline{swift}{reloadData()} function, which causes all cell heights to be calculated again.

When doing manual calculations, it was trivial to optimize the calculations for the type of cells the application should be able to render. For example, media cells had a fixed height and calculations were not necessary in that case, as the pre-defined constant could be returned instead (the vertical margins should still be added to it).

\subsubsection*{Performance changes}
Running the performance tests yielded the following results:
\itkIncludeImage{test-3}{Performance test results after migrating to manual cell height calculations}

The manual cell height calculations increased the average frame rate by 4.3 frames per second and the frame rate stability by 7.5 percent while keeping the resource usage the same. The optimization can be counted as a huge success as there was another 10.6\% increase in the average frame rate without affect the resource usage. 

\subsubsection*{Code examples}
The cell height calculations overwriting had to occur in the function displayed below (this example shows how it was previously when automatic calculations were used).
\begin{listing}[H]
  \caption{Interface function for overwriting cell height calculations}
  \begin{minted}{swift}
    func tableView(_ tableView: UITableView, heightForRowAt indexPath: IndexPath) -> CGFloat {
      return UITableViewAutomaticDimension
    }
  \end{minted}
\end{listing}

Calculating the height for media item cells was trivial as they had a fixed height and fixed vertical margins. Below is an example on how the height for media item cells was calculated.
\begin{listing}[H]
  \caption{Calculating media cell's height manually}
  \begin{minted}{swift}
    let message = self._messages[indexPath.row]
    if let mediaItems = message.mediaItems {
      let baseHeight = (mediaItems.count == 1) ? Pairby.MessageUI.HEIGHT_MEDIA_ONE : Pairby.MessageUI.HEIGHT_MEDIA_MULTIPLE
      let verticalMarginsSum = (2 * Pairby.MessageUI.MARGIN_VERTICAL_WRAP)
      return (baseHeight + verticalMarginsSum)
    }
  \end{minted}
\end{listing}

Calculating the height for th text cells was more difficult as the text height varied depending on the number of lines in the text. The number of lines was dependant on the length of the text and the width of the screen, as described in the specification. Below is an example on how to calculate the height for the text message cell from the text.
\begin{listing}[H]
  \caption{Calculating text cell's height manually}
  \begin{minted}{swift}
    let maximumWidth = (self._tableView.frame.size.width - (2 * Pairby.MessageUI.MARGIN_HORIZONTAL) - Pairby.MessageUI.MARGIN_HORIZONTAL_WRAP_DYNAMIC - Pairby.MessageUI.MARGIN_HORIZONTAL_WRAP_FIXED)
    let verticalMarginsSum = (2 * Pairby.MessageUI.MARGIN_VERTICAL + 2 * Pairby.MessageUI.MARGIN_VERTICAL_WRAP)
    let baseHeight = ceil(message.message!.heightWithConstrainedWidth(width: maximumWidth, font: Pairby.MessageUI.TEXT_FONT))
    return (baseHeight + verticalMarginsSum)
  \end{minted}
\end{listing}

%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% Cell height caching % % REVIEWED | T: + | G:   %
%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Cell height caching}
Even though the efficient manual calculations did yield a noticeable increase in performance, it was possible to improve it even further by caching the calculation results. This means the calculations for each cell should only be run once.

\subsubsection*{Theoretical benefits}
This optimization would not provide any performance benefits the first time the user scrolls the messages list. This would, however, improve performance when the user scrolls back to regions where they have already scrolled.

\subsubsection*{Performance changes}
Running the performance tests yielded the following results:
\itkIncludeImage{test-4}{Performance test results after adding caching to manual cell height calculations}

As expected, the performance did improve. The average frame rate increased by 3.9 frames per second and the stability by 6.95 percent. The average processor, graphics processor and memory usage, similarly to previous tests, remained the same. The average processor usage did decrease by 1.91\%, but that deviation is too small to draw any conclusions from. In conclusion, the average frame rate increased by 8.7\%, stability by 6.95\% and the resource usage stayed the same.

\subsubsection*{Code examples}
The cache was a simple \mintinline{swift}{Dictionary} where the key was the cell's row index and the value was the height as a \mintinline{swift}{CGFloat}. Below is an example of the whole cycle of calculating, caching and using the cached value. The calculations have been omitted from this code, they can be seen in section \ref{subsection:ManualCellHeightCalculations}. 
\begin{listing}[H]
  \caption{Caching and using cached height}
  \begin{minted}{swift}
    private var _heightCache: [Int: CGFloat] = [:]

    func tableView(_ tableView: UITableView, heightForRowAt indexPath: IndexPath) -> CGFloat {
        if let height = self._heightCache[indexPath.row] { return height }
        let message = self._messages[indexPath.row]

        if let mediaItems = message.mediaItems {
            let Height = (mediaItems.count == 1) ? Pairby.MessageUI.HEIGHT_MEDIA_ONE : Pairby.MessageUI.HEIGHT_MEDIA_MULTIPLE
            let Margins = (2 * Pairby.MessageUI.MARGIN_VERTICAL_WRAP)
            self._heightCache[indexPath.row] = (Height + Margins)
            return self._heightCache[indexPath.row]!
        }

        let MaxWidth = (self._tableView.frame.size.width - (2 * Pairby.MessageUI.MARGIN_HORIZONTAL) - Pairby.MessageUI.MARGIN_HORIZONTAL_WRAP_DYNAMIC - Pairby.MessageUI.MARGIN_HORIZONTAL_WRAP_FIXED)
        let Margins = (2 * Pairby.MessageUI.MARGIN_VERTICAL + 2 * Pairby.MessageUI.MARGIN_VERTICAL_WRAP)
        let Height = ceil(message.message!.heightWithConstrainedWidth(width: MaxWidth, font: Pairby.MessageUI.TEXT_FONT))
        self._heightCache[indexPath.row] = (Height + Margins)
        return self._heightCache[indexPath.row]!
    }
  \end{minted}
\end{listing}


%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% Optimizing image sizes % % REVIEWED | T: + | G:   %
%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Optimizing image sizes}
\label{sec:optimizing-image-sizes}
As specified in the specification section, the test data contained about 25\% of media messages, all of which contained 1 to 3 images (both static and animated). Since images make up a relatively large portion of all messages in the test data set, it was decided to look into optimizing them by resizing them to the correct size before displaying them in the user interface. The idea was a collaboration between the author and the thesis' supervisor Gary Planthaber.

PINRemoteImage already provided the functionality to do image processing and caching of the processed images, but that was only possible for non-animated images. It was decided to not optimize the animated images optimized and let the system handle them as they are.

\subsubsection*{Theoretical benefits}
The pre-processing should make the images the correct size before they reach the user interface and if the static images would no longer need any up- or downscaling in terms of processing, this should theoretically improve the rendering times of the media cells and the performance when the scrollable view is in motion.

\subsubsection*{Performance changes}
Running the performance tests yielded the following results:
\itkIncludeImage{test-5}{Performance test results after adding pre-processing of images}

The change in the average frame rate did not display a big change (improvement of 1.7 frames per second), but the frame rate stability increased by 30.5\%, which was a huge improvement. The processor and graphics processor usage did not display a noticeable change. The memory usage, however, changed dramatically. The average memory usage increased by 136\%, from 33 megabytes to 78 megabytes, compared to the previous test. This average memory increase is easily explainable by the fact that the image processing uses a lot of memory and the application had to start a lot of image processing processes when the scroll speed was nearing its maximum.

The average memory usage does seem high, but since it is temporary for the duration of the fast scroll, it should definitely be worth the huge improvements in the frame rate stability.

\subsubsection*{Code examples}
Below is an example of how the image was resized to a given size, using iOS' built-in classes. The parameters of the function were the original UIImage and the expected size of the new image. Since the handled images are always square, only one dimension's length was enough to specify the size.
\begin{listing}[H]
  \caption{Resizing an UIImage to a specified size}
  \begin{minted}{swift}
    func processImage(image: UIImage, size: CGFloat) -> UIImage {
      let scaledSize = (size * UIScreen.main.scale)
      let imageRect = CGRect(x: 0, y: 0, width: scaledSize, height: scaledSize)

      UIGraphicsBeginImageContext(imageRect.size)

      let sizeMultiplier: CGFloat = (scaledSize / image.size.width)

      var drawRect = CGRect(x: 0, y: 0, width: image.size.width * sizeMultiplier, height: image.size.height * sizeMultiplier)
      if (drawRect.maxX > imageRect.maxX) { drawRect.origin.x -= (drawRect.maxX - imageRect.maxX) / 2 }
      if (drawRect.maxY > imageRect.maxY) { drawRect.origin.y -= (drawRect.maxY - imageRect.maxY) / 2 }

      image.draw(in: drawRect)

      let processedImage = UIGraphicsGetImageFromCurrentImageContext()
      UIGraphicsEndImageContext()

      return processedImage!
    }
  \end{minted}
\end{listing}


%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% Layer rasterization % % REVIEWED | T: + | G:   %
%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Rasterization of cell layers}
Rasterization in the iOS view rendering context means turning the view into a cacheable bitmap that can be used in later rendering more efficiently. Rasterization of views was a built in feature of the \mintinline{swift}{CALayer} class. Every view has a \mintinline{swift}{CALayer} instance, accessible through the \mintinline{swift}{layer} property. That property is inherited from the \mintinline{swift}{UIView} base class.

\subsubsection*{Theoretical benefits}
All the views except the ones containing animated images are static once rendered and will not change in the UI. This was one of the requirements to reap benefits from layer rasterization. Rasterization process consumes more resources and time than regular rendering at first, but once done, the view would be handled much more efficiently by the rendering engine due to the fact that the graphics processor can use the cached bitmap instead of re-drawing the view.\cite{MovingPixelsOntoTheScreen}

\subsubsection*{Performance changes}
Running the performance tests yielded the following results:
\itkIncludeImage{test-6}{Performance test results after enabling rasterization of the views}

Cell rasterization did not provide any of the expected performance improvements. The average frame rate decreased by 2.8 frames per second and the frame rate stability went down by almost 30\%.

This shocking result confirmed that more research needed to be done about the proper usage of rasterization. These benefits are investigated in the next section.

\subsubsection*{Code examples}
Enabling the rasterization of the cell views required adding only two lines of code. There is an example of the two lines below. The first one enabled rasterization and the second one told the rasterization mechanism to use a certain scale to compensate for the fact that some devices are using retina screens and require scaling when being rasterized.
\begin{listing}[H]
  \caption{Rasterizing views}
  \begin{minted}{swift}
    self.view.layer.shouldRasterize = true
    self.view.layer.rasterizationScale = UIScreen.main.scale
  \end{minted}
\end{listing}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% Avoiding offscreen rendering % % REVIEWED | T: + | G:   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Avoiding unnecessary offscreen rendering}
\label{sec:avoiding-unnecessary-offscreen-rendering}
Offscreen rendering means drawing the view into a new buffer (bitmap cache) which is offscreen (not on the screen) before drawing that buffer on the screen. The conventional way of drawing views is to draw them subview by subview directly onto the screen.\cite{MovingPixelsOntoTheScreen}

Offscreen rendering consumes more resources and is slower than conventional rendering, but it can be beneficial to performance due to the fact that the resulting bitmap can be cached and reused. The caching and reusing will only work and improve performance when the view does not change that often. The ideal case would be a view that never changes (is immutable). If a view were to change often, for example a view containing an animated image (GIF), then the drawing to bitmap would have had to be done every time the animated image's frame changed and none of the cached buffers could be reused.

Layer rasterization was one example of manually triggering offscreen rendering on a whole view. Offscreen rendering can also be triggered automatically by Core Animation. This would happen for example when a mask is directly or indirectly applied to a layer. That would also force the graphics processor to do offscreen rendering in order to apply that mask. This will in turn, as stated earlier, put unnecessary burden on the GPU.\cite{MovingPixelsOntoTheScreen}

In order to get benefits from the rasterization of layers, all other direct or indirect causes of offscreen rendering should be avoided. This is theoretically why the previous optimization did not work - some indirect causes of offscreen rendering were invalidating the rasterization cached bitmap. For example, some indirect causes of offscreen rendering are applying shadows and corner radiuses to the layer, the latter of which the test project does for all cells to create the chat bubble effect.\cite{MovingPixelsOntoTheScreen}

\subsubsection*{Theoretical benefits}
The theoretical benefits were reduced resource usage and increased performance (better average frame rate, higher frame rate stability). These should have also resulted in smoother scrolling.

\subsubsection*{Performance changes}
Running the performance tests yielded the following results:
\itkIncludeImage{test-7}{Performance test results after removing unnecessary offscreen rendering}

Avoiding unnecessary offscreen rendering proved to be beneficial to performance and graphics processor usage. The average frame rate increased by 3.1 and the stability increased by almost 10\%. While the average processor usage did not change much, the average graphics processor usage showed a huge drop of 29\%. The average memory usage, however, increased by a whopping 30\% (from 78 megabytes to 101.5 megabytes). 

\subsubsection*{Code examples}
In order to work around using \mintinline{swift}{CALayer}'s corner radius when drawing text cell views, the background with a corner radius was drawn manually. This was done by creating a custom wrapper view for the text that was able draw the rounded corner background efficiently. Below is the code for that view, which shows the background color being customizable and the draw method being only aware of drawing a rectangle with rounded corners.
\begin{listing}[H]
  \caption{Custom wrapper view for text message view with rounded corners that avoids offscreen rendering}
  \begin{minted}{swift}
    class NoOffscreenRendering_TextCell_LabelWrapView: UIView {
      private var _fillColor: UIColor?

      override init(frame: CGRect) {
        super.init(frame: frame)
        self.backgroundColor = Pairby.Colors.GRAY_BG
      }

      convenience init() {
        self.init(frame: CGRect.zero)
      }

      required init(coder aDecoder: NSCoder) {
        fatalError("This class does not support NSCoding")
      }

      func fillWith(color: UIColor) {
        self._fillColor = color
        self.setNeedsDisplay()
      }

      override func draw(_ rect: CGRect) {
        UIBezierPath(roundedRect: rect, cornerRadius: 15.0).addClip()
        self._fillColor?.setFill()
        UIBezierPath(rect: rect).fill()
      }
    }
  \end{minted}
\end{listing}


%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% AsyncDisplayKit % % REVIEWED | T: + | G:   %
%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{AsyncDisplayKit}
AsyncDisplayKit is an iOS framework built on top of UIKit that keeps even the most complex user interfaces smooth and responsive.\cite{IntroducingAsyncDisplayKit} The library's goal was to make even the most complex views have a 60 frames per second rendering in iOS applications by moving the rendering off the main thread.

In order to test this out, a replica of the best case scenario view was built, identical to the one built with UIKit. This meant only having text message views. Media messages were replaced with text. Instead of UIKit classes, AsyncDisplayKit's classes and methodologies were used.

\subsubsection*{Theoretical benefits}
The expected test results after applying AsyncDisplayKit's classes and methodologies was performance at least equivalent to that of UIKit's best case scenario. The expected benefits would be less resources consumed due to the better use of threads.

\subsubsection*{Performance changes}
Running the performance tests yielded the following results:
\itkIncludeImage{test-8}{Performance test results with AsyncDisplayKit's classes and methodologies}

Not only was the performance noticeably worse compared to the UIKit's best case scenario, the time it took to open the view initially was unacceptable (more than 10 seconds to load all the AsyncDisplayKit's classes and views). UIKit's best case scenario view opened instantly, with no main thread holdups.

Scrolling performance wise, it performed much worse than UIKit's UITableView. The average frame rate did not meet the 60 frames per second expectation. The frame rate stability was also not a solid 100 percent. The actual recorded values were 58.5 frames per second and 97.5\% respectively. CPU usage was 26\% higher than that of UIKit's best case scenario. Graphics processor and memory usage did not change notably.

Due to the best case scenario results being so poor, it was decided not to continue trying to make AsyncDisplayKit work as an optimization.

\subsubsection*{Code examples}
Below is a code example of how cells were created and returned to be used in the user interface using AsyncDisplayKit's classes and functions.
\begin{listing}[H]
  \caption{Creation and use of AsyncDisplayKit's cell views}
  \begin{minted}{swift}
    func tableNode(_ tableNode: ASTableNode, nodeBlockForRowAt indexPath: IndexPath) -> ASCellNodeBlock {
      let message = self._messages[indexPath.row]
      return {
        let cell = ASTextCellNode()
        cell.text = (message.message != nil) ? message.message! : "Media message with ID [\(message.id)]"
        return cell
      }
    }
  \end{minted}
\end{listing}

%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% End result comparisons % % REVIEWED | T:   | G:   %
%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{End result}
The end result was considered to be the result of applying all the optimizations cumulatively from recycling cells to avoiding unnecessary offscreen rendering. The optimizations included reusing cells, using static views, manual height calculations, height caching, image optimizations and avoiding unnecessary offscreen rendering. This meant considering the end result to be the product of \autoref{sec:avoiding-unnecessary-offscreen-rendering}.

\subsection{Compared to the worst case scenario}
To better compare the end result against the worst case scenario, a table comparing the worst case scenario results from \autoref{sec:worst-case-scenario} against the results from \autoref{sec:avoiding-unnecessary-offscreen-rendering} was created and is displayed below.
\itkIncludeImage{worst-vs-end}{Worst case scenario results compared against the end result's test results}

The duration of the test decreased from 105.5 seconds to 87.4, which is a 17\% decrease. This can be explained by the increased performance (better frame rate), as the processors could finish rendering all the required frames faster.

The average frame rate increased from 26.0 to 53.4, which is a tremendous 105\% increase, effectively doubling the number of frames each second. The cap and goal of 60 frames per second was not achieved.

The frame rate stability index improved more than 2.6 times, from the starting value of 23.6\% to 87.1\%. This custom measurement point effectively showed that not only did the average frame rate increase, the time spent within 20 percent of that average also increased by a big margin.

Average processor and graphics processor both decreased by a noticeable margin. Average processor usage went from 69.4\% to 57.8\%, which is a 11\% decrease (comparative decrease of 16\%). Graphics processor's average usage decreased from 65.7\% to 40.1\% (comparative decrease of 38.9\%). Processors' usages went down while performance improved, which was the goal.

Average memory usage increased by 2.6 times, from an average of 28 megabytes to 101.5 megabytes. The main reason for this increase was image processing. The biggest increase in average memory usage can be traced to \autoref{sec:optimizing-image-sizes}, where image optimizations were introduced. The mentioned optimizations increased average frame rate and frame rate stability while sacrificing memory usage. The memory usage increase is temporary, while the processing is first done and after properly caching the processed images, the memory usage will decrease.

To conclude the comparison between the worst case scenario and the end result, it can be said that the optimizations were a success. The average frame rate more than doubled and the frame rate stability almost quadrupled. Average usages of both the graphics processor and the central processor decreased. Memory usage did increase by a large margin, but as the increase is temporary and will not affect the application's memory usage for the whole duration of the application's life, its importance can be disregarded. The optimizations can be called useful, when comparing them against the worst case scenario, as the performance improved while resource usage decreased.

\newpage
\subsection{Compared to the best case scenario}
To compare the end result against the goal, which was the best case scenario, another table was created. The table displayed the differences between the test results from \autoref{sec:best-case-scenario} against the results from \autoref{sec:avoiding-unnecessary-offscreen-rendering}. The created table, which also contains comparative percentages, is displayed below.
\itkIncludeImage{best-vs-end}{Best case scenario results compared against the end result's test results}

The duration of the end result was still 21 seconds longer than that of best case scenario's. As was the case with the worst case scenario, this can be explained by the changes in performance. When the necessary frames are rendered faster, the duration will be less. This in turn is caused by the fact that the test ends when the scroll reaches the bottom.

The best case scenario's average frame rate displayed that the cap is 60 frames per second and it is possible to achieve it with views that have very little complexity. The end result did not achieve the same average frame rate. Instead, the tests recorded the average frame rate to be 53.4. Even though it was proven that 60 frames per second can be achieved, the end result with all known optimizations could not reach it.

The frame rate stability for the best case scenario proved the possibility of having a stability index of 100 percent. The end result did not manage to reach the 100 percent. Instead, the tests recorded a result of 87.1\%. As explained previously, this means that 87\% of the time was spent within 20 percent of the average frame rate, which was 53.4 frames per second. The 87.1\% stability was still an acceptably good result.

Comparing the average central processor and graphics processor usage's in the best case scenario and end product's test results showed a shocking difference. Average processor usage was only 16\% in the best case scenario, but 57.8\% in the end result, which is about 3.5 times higher. The change was less drastic for the average graphics processor usage. It only increased from 23.8\% to 40\%, which is still quite an increase, but nothing worrying. These changes can be explained by the fact that the best case scenario did not have any complex views nor images in it. The processors' average usages did increase by a noticeable amount, but still stayed within reasonable bounds and did not come close to their upper limit.

The average memory usage for the best case scenario was about the same as for all the optimizations until \autoref{sec:optimizing-image-sizes}, where image optimizations were introduced. After that point, the memory usage increased and the effect was worsened by the additional image processing introduced in \autoref{sec:avoiding-unnecessary-offscreen-rendering}. The average memory usage hovered near 101 megabytes after these optimizations, compared to the original 31 megabytes, as recorded in the best case scenario. As also mentioned in the previous subsection, end result compared to the worst case scenario, the memory usage would not stay at that recorded point, it would eventually settle down back to 31 megabytes when all the image processing is done. The average memory usage increased more than 3 times, but due to the fact that it is a temporary state, it is not considered a deal breaker.

%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
% Summary % % REVIEWED | T: + | G:   %
%%%%%%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Summary}
The goal of the thesis was to find optimizations that would improve the Pairby iOS application's message list view's UITableView component's performance. In total, 8 different optimization methods were realized and benchmarked. 6 of the found optimizations had the expected performance boosting effect. 2 of the optimizations did not provide the expected performance enhancing benefits, but were still included in this thesis since their failure reasons became a basis for the next optimizations.

The practical part of the thesis started by creating two benchmarking points called the worst case scenario and the best case scenario. Their goal was to represent the worst possible performance and the best possible performance. The worst case scenario with its  view became the starting point for all optimizations while the 60 frame per second performance recorded in best case scenario view became the ultimate goal.

The whole optimization process was split into sections, each covering one specific optimization technique. Each section had three subsections in addition to the short introduction: theoretical benefits, performance changes and code examples. This structure allowed each technique to be explained in adequate depth in a similar manner across all sections.

Even though the optimizations were handled individually per section, all optimizations were applied accumulatively to the main project throughout the optimization process. The purpose of that was to ultimately create a view which had all the optimizations and eventually mark it as the end result.

To draw conclusions from done work, the end result, which was a result of all found and applied optimizations, was compared to the worst and best case scenarios.

Compared to the worst case scenario, the improvements were huge. The average frame rate increased by 105\% and ended up at a measured value of 53.4 frames per second. The frame rate stability (time spent within 20\% of the average frame rate) increased from 23\% to 87\%, which is a huge improvement. The average central processor and graphics processor usages decreased by 11.5\% and 25.6\% respectively. The respective values for the average CPU and GPU usages measured for the end result were 57.9\% and 40.2\%. The average memory usage showed a huge increase from 28.0 megabytes to 101.5 megabytes. That increase can be explained by the addition of image processing, which improved average frame rates and frame rate stability at the cost of temporarily using more memory. When comparing the end result to the worst case scenario, all the performance related parameters increased by more than two times while the average CPU and GPU usage went down and the memory usage showed a temporary increase.

The end result did not achieve the performance numbers measured and set as a goal in the best case scenario tests. The best case scenario showed that an average frame rate 60 frames per second and a frame rate stability of 100\% is the best possible performance. The end result benchmarks recorded an average frame rate of 53.4 frames per second and a frame rate stability of 87.1\%. Both of those metrics came close to 90\% of the goal, which can be counted as a success. The average CPU, GPU and memory usages increased by a lot. Average CPU usage increased from 16.1\% to 57.9\%, GPU usage from 23.9\% to 40.2\% and memory usage from 31.0 to 101.5 megabytes. When comparing the end result to the set goal, about 90\% of the performance goal was achieved, which can be counted as a success.

The author finds that the user experience provided by the end result is great. The end result offered about 90\% of the best possible performance and the author finds that a frame rate of 53.4 frames per second is indistinguishable from 60 frames per second by an average user. This means that the goal of the thesis, which was to offer a good user experience related to scroll performance, was achieved.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% After-content sections %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%
% Figures %
%%%%%%%%%%%
\newpage
\phantomsection
\addcontentsline{toc}{section}{List of Figures}
\listoffigures

%%%%%%%%%%%%%%
% References %
%%%%%%%%%%%%%%
\newpage
\phantomsection
\addcontentsline{toc}{section}{References}
\bibliography{thesis}
\bibliographystyle{plain}

\end{document}
